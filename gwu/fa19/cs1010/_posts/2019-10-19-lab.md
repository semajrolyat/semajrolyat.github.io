---
layout: post
title:  "Computer Vision"
date:   2019-10-19 00:00:00 -0400
schedule:   2019-10-19 00:00:00 -0400
categories: [GWU]
docclass: "lab"
gwclass: "cs1010"
term: "fa19"
---
<head>
  <link href="/css/syntax.css" rel="stylesheet">
</head>

# Lab 5 - Computer Vision

## Introduction

If you consider for a moment how much of human culture and communication is driven by visual communication or expression, it should be evident that vision is a tremendous capability and visual imagery can contain significant amounts of information.     

Computer vision is the domain of computational science dedicated to using automated processes to extract and operate on data produced by imaging sensors.  Imaging sensors may gather data in spectrums that exceed human sensory limitations, so computer vision is not strictly limited to what humans might associate with sight.  Beyond the visual spectrum, sensors may detect x-rays, radio waves, infra-red, or other types of radiation and they may be active or passive systems.  As it turns out, our environment is filled with information across a wide spectrum of radiation much of which humans are incapable of sensing.

> In the Basic Device Development lab, we built a basic device that relied on an ultrasonic sensor and then watched the data flow from the sensor on an oscilloscope.  The trace of the signal on the oscilloscope was a rudimentary form of computer vision.

Computers allow us to gather and store large amounts of data, to visualize data in a variety of ways, and to automatically extract, process, and make decisions on the information contained in the data.

> In the Machine Learning lab, we discussed that Machine Learning has a wide variety of applications.  Due to the volume and complexity of data in imagery, computer vision is an obvious application for machine learning (ML) and any work involving computer vision now generally requires some background in ML.        

### Applications

The applications of computer vision are diverse and wide ranging.  Some of the more widely known applications are facial recognition, automated vehicle control, and satellite observations such as using the Hubble telescope to observe far off phenomena or using downward looking satellites to observe phenomena on Earth.  Beyond these applications, researchers are looking at other applications due to the wide availability of crowd-sourced photographic data.

Due to the increase in computing power and decrease in computing costs, there is an growing field of initiatives involving computer vision that are driven by novel yet important problems.   One such initiative is to identify whales through crowd-sourced photographic data called [Flukebook](https://www.flukebook.org/).  There are also public competitions like the [Kaggle Competitions](https://www.kaggle.com/competitions) where sponsered problems in computer vision are crowd-source to the public.

### Image Data

Every image consists of a number a pixels.  A _**pixel**_ is a single illumination unit in an image.  Each pixel consists of one or more channels (values) that represent the brightness or intensity of a color.  We may have one channel which encodes the intensity of the pixel on a scale of dark to light or we may have a number of channels which encode the intensity of a particular color on a scale of no intensity to full intensity.  

The range of intensity is fixed from none to full, so there are a variety of fixed ranges that are used depending on hardware and image standard.  Because the range is fixed, we can model it in the range or real values [0,1] where 0 represents no intensity and 1 represents full intensity.  However, for practical reasons, these ranges may also be commonly represented as [0,255] instead.

> A byte is 8 bits.  2^8 is 256, so the range [0,255] is actually [0,256-1] or [0,2^8-1].  Why this range is used is not exactly self-evident; however, it has a close relationship with computer memory.

#### Grayscale

Grayscale representation uses only a single value per pixel to represent the intensity of a pixel.  With only one channel of intensity, we can only represent the brightness of light and not the color of light.  If we only have a single value 0 and 1, we represent black as 0, the absence of intensity, and we represent white as 1, full intensity.

#### RGB

Color images use multiple channels per pixel to represent color intensity.  The format is called RGB because it consists of Red, Green, and Blue channel.  Additive color mixing allows for these three colors to be blended with varying intensities to produce any color in the visible spectrum. 

#### Alpha Channel
RGB may sometimes include another channel called the Alpha channel which extends the format to ARGB or RGBA depending on the file structure.  The alpha channel contains transparency information which dictates how opaque/transparent a color data for a pixel is.  The alpha channel is important when blending together multiple images when layered on top of one another.



## Python Image Library (PIL/Pillow)

We will use the Python image library (PIL) to perform image operations.  This library has a wide range of capabilities and allows a Python programmer to extract and manipulate data in code.  Through PIL we can programmatically recreate operations common to popular, commercial image manipulation software.     

### ```PIL``` Fundamentals

#### Loading an Image

To get started, we need an image to work with and we need to load that image into Python.  For a simple example, download [colors.png]({{ "/gwu/fa19/cs1010/assets/lab5/colors.png" | absolute_url }}) and save it to your lab folder for this week.  Colors is the additive color image we discussed earlier:

![colors.png]({{ "/gwu/fa19/cs1010/assets/lab5/colors.png" | absolute_url }})

To load the image, we need to import the ```Image``` module from ```PIL``` and then use the ```open``` method from ```Image``` to read in the image into memory.  ```open``` takes the filename of the image as a parameter and returns a reference to the image data.

```Python
from PIL import Image

img = Image.open("colors.png")
```

In the above example, ```img``` contains a reference that we can work with to interact with the image data in a variety of ways.

#### Plotting an Image

While ```PIL``` has that ability to render an image into a window, ```PIL``` is specifically designed to work with ```matplotlib``` which is a much more flexible way to render images in Python.  

```Python
from PIL import Image
import matplotlib.pyplot as plt

img = Image.open("colors.png")

plt.imshow(img)
```

The ```matplotlib.pyplot``` function ```imshow``` will render directly into an IPython context.  If you are using Spyder, you should see the ```colors``` image rendered into the console window.

#### A Function to Create a Figure with No Axes

By default, ```matplotlib``` adds axes and whitespace to a figure.  We really want to preserve the image data without these additions.  The following function allows us to generate a figure with none of these additions:  

```Python
def setup_figure(sz):
    # prep a figure with no axes
    fig = plt.figure(figsize=(sz[0],sz[1]))
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.margins(0,0)
    ax.axis('off')
    ax.xaxis.set_major_locator(plt.NullLocator())
    ax.yaxis.set_major_locator(plt.NullLocator())
    fig.add_axes(ax)
    return fig, ax
```

The parameter ```sz``` is a list composed of two values with the first value represents the width of the figure in inches and the second value represents the height of the figure in inches.

The following short program uses ```setup_figure```.  The code computes the size of the new image from the size information of the original image to ensure that the new image has the same dimensions as the original image.

```Python
from PIL import Image
import matplotlib.pyplot as plt

# Load an image
img = Image.open("colors.png")

# Calculate dimensional information from the image
width, height = img.size
dpi = img.info["dpi"][0]
sz = [width/dpi, height/dpi]

# Use the setup_figure function to create an figure with no axes
fig, ax = setup_figure(sz)

# Show the image
plt.imshow(im2)
```

#### Saving a Plot

We can save a plot generated by matplotlib by using the ```savefig``` function built into ```matplotlib.pyplot``` which only requires a filename.  However, if we need to ensure the figure has specific dimensions and does not contain padded whitespace, we should pass some of the optional parameters that control padding.  We should also pass the ```dpi``` we computed in the previous example so that the figure saved retains that expected dimensions.  The following code meets the necessary criteria:

```Python
plt.savefig("temp.png", bbox_inches='tight', pad_inches=0, transparent=True, dpi=dpi)
```

#### Warmup Exercise

Write a Python program named ```exercise1.py``` and save it to today's lab folder.  ```exercise1.py``` must load ```colors.png```, plot the image using ```matplotlib```, and save the image to a file ```colors2.png```.  ```colors2.png``` must be an exact copy of ```colors.png```.

### Color Operations

We can access and operate on individual pixels; however, this can be an inefficient approach.  ```PIL``` provides some very powerful operations that allow us to perform operations on an entire image or on a specific color channel.  

#### Converting Between Color Representations

The ```convert``` function returns a converted copy of an image.  It can be used to convert between color modes given a specification.  ```'RGBA'``` converts the image to the RGBA standard while ```'L'``` converts the image to a greyscale standard.

For example, the following code converts ```img``` to ```RGBA``` color format.  It can be used to add an alpha channel to an image that does not have an alpha channel.

```Python
im2 = img.convert('RGBA')
```

Alternatively, the following code converts ```img``` to a greyscale format:

```Python
im2 = img.convert('L')
```

#### Split an Image Into Individual Color Channels

Recall that a color image consists of three to four independent color channels.  Specifically, the RGBA format consists of four channels: red, green, blue, and alpha.  We can split the image into these independent channels using the ```split``` function that is built into the ```Image``` module.

```Python
im2 = img.convert('RGBA')
r,g,b,a = im2.split()
```

In the above example, the red channel is stored in ```r```, the green channel is split into ```g```, the blue channel is split into ```b```, and the alpha channel is split into ```a```.  Convert is called before splitting to ensure that the image is in the correct format and that the channels are mapped to the correct variables.  Alternatively, we can perform the same operation without the intermediate variable:

```Python
r,g,b,a = img.convert('RGBA').split()
```

Each of these channels is a greyscale image.  If we render one of the channels, we will not see colors but shades of grey as that channel only contains intensity values for each pixel.  For example, we can split ```colors.png``` into individual channels and render only the red channel:

```Python
from PIL import Image
import matplotlib.pyplot as plt

# Load an image
img = Image.open("colors.png")

r,g,b,a = img.convert('RGBA').split()
plt.imshow(r, cmap = 'Greys_r')
```

> ```cmap``` is shorthand for colormap.  We don't generally need to provide it for RGB based images. For greyscale images we need to provide the value ```Greys_r``` to render in grey; otherwise, ```matplotlib``` uses an arbitrary color scheme.  

This program should produce an image that contains only the red channel in a greyscale format:

![red channel]({{ "/gwu/fa19/cs1010/assets/lab5/redmask.png" | absolute_url }})

#### Merging Color Channels

We can compose an image from individual channels using the ```merge``` function.  ```merge``` requires that all of the channels have the same number of elements.  The following is a basic example of ```merge``` assuming we have channels ```r, g, b, a``` all of with the same size:

```Python
im2 = Image.merge("RGBA", (r,g,b,a))
```

The following is a trivial but comprehensive example:

```Python
from PIL import Image
import matplotlib.pyplot as plt

# Load an image
img = Image.open("colors.png")

r,g,b,a = img.convert('RGBA').split()
im2 = Image.merge("RGBA", (r,g,b,a))

plt.imshow(im2)
```

The above program should produce an image that is exactly like the original ```colors.png```.

#### Logical Color Operations

The ```PIL``` library includes a mathematics module called ```ImageMath``` that allows us to perform logical operations on images.  Included in ```ImageMath``` is the ```eval``` function which allows a programmer to perform complex bulk operations on the entire image.  The ```eval``` function has a lot of flexibility; however, we will strictly focus on a few logical operations to filter or change colors.

To access these tools, we must import the ```ImageMath``` module.  For example:

```Python
from PIL import Image, ImageMath
```

If we wish to display only the red channel from the original image as red, we can split the image into RGBA channels and then use the ```eval``` function to perform logical operations to select colors and filter out unwanted channels.  ```eval``` operates on a string.  Consider this example:

```Python
r,g,b,a = img.convert('RGBA').split()
a = ImageMath.eval("convert(r&a, 'L')", r=r,a=a)
g = ImageMath.eval("convert(g&0, 'L')", g=g)
b = ImageMath.eval("convert(b&0, 'L')", b=b)
im2 = Image.merge("RGBA", (r,g,b,a))
```

In the above example, the code selects only the red channel from the image, zeroes out any other channels, and then recombines the channels into an RGBA image that renders in color.  We have seen the first and last lines before; however, let's look at the other lines.

```Python
g = ImageMath.eval("convert(g&0, 'L')", g=g)
b = ImageMath.eval("convert(b&0, 'L')", b=b)
```
These two lines perform the logical ```and``` of zero with every value in the green and blue channels.  If we perform a logical ```and``` of any value with zero, the result is zero.  We are effectively converting all values in the green and blue channels to zero meaning the green and blue channels are cleared.

```Python
a = ImageMath.eval("convert(r&a, 'L')", r=r,a=a)
```

This line is a little more complex.  To fix the alpha channel, we only want to maintain transparency for pixels that are not transparent (non-zero) and have a red value.  To achieve this, this operation performs a logical ```and``` between the red and alpha channels.  This operation zeros out the transparency of a pixel that has either green or blue intensity but does not affect a pixel that has red intensity.  This operation computes the intersection of where alpha and red both share pixels with some intensity.

Note that we do not perform any operation on the red channel.  Red used in the alpha filtering process, but we never overwrite the red channel unlike the other channels.

#### Inverting

For a greyscale image, we may need to swap dark with light intensities and vice-versa.  This is akin to creating a photographic negative of an image.  This operation can be very useful if our original image uses dark values with high opacity to indicate the presence of something and white or transparent to represent the absence of something.

In order to access the invert operations, we need to import the ImageOps module:

```Python
from PIL import Image, ImageMath, ImageOps
```

The following example demonstrates the ```invert``` operation.  If the ```blackonwhite``` image consists of black lines on white paper, the ```invert``` operations will produce an image ```whiteonblack``` which is analogous to white lines on black paper.

```Python
whiteonblack = ImageOps.invert(blackonwhite)
```

#### Intersecting

The intersection of two channels is the set of pixels that where both channels have non-zero values for a given pixel.  We have already performed an intersection in the example dealing with detecting the alpha channel where red pixels have values.  

More generally, we can also perform this on greyscale images that have only binary values of pure black and pure white.  The intersection between two binary greyscale images will be a greyscale image that consists of only the pixels that are white in both source images.

For example, suppose we have two greyscale images, ```img1``` and ```img2```.  We can generate the intersection by using the logical ```and``` operation as we did before:
```python
img_intersection = ImageMath.eval("convert(a&b,'L')", a=img1, b=img2)
```

Alternatively, we could also find the intersection of white pixels in ```img1``` and black pixels in ```img2``` using the following code:
```python
img_intersection = ImageMath.eval("convert(a&~b,'L')", a=img1, b=img2)
```

> The tilde in the conversion string indicates a logical ```not```.  We can read this operation as find all pixels where that pixel is white in ```img1``` and is black in ```img2```.


#### Layering Images

We may operate on individual images and even on individual channels; however, most visualizations today use a layering technique where we might want to overlay one image on top of another.  Generally this is called layering and the individual images we composite are called layers.  This capability is really only possible with the addition of transparency through the alpha channel.

We can layer a foreground over a background image using the ```alpha_composite``` function.  Usage for ```alpha_composite``` is illustrated with the following example:

```Python
from PIL import Image
import matplotlib.pyplot as plt

img_bg = Image.open("flood.png")

img_fg = Image.open("roadmask.png")

im3 = Image.alpha_composite(img_bg, img_fg)

plt.imshow(im3)
```

The resulting image will consist of any opaque pixels from ```img_fg``` being copied on top of (and blended with if not fully opaque) the corresponding pixels in ```img_bg```.

## The Houston-Harvey Flooding

Hurricane Harvey made landfall on August 25 and 26, 2017 and moved into the Houston area on August 27. On August 28, controlled releases began from both reservoirs which fed into Buffalo Bayou (south and east of the reservoirs) to releve the danger of flooding north and west of the reservoirs. On August 29, water from Addicks reservoir began to overtop into neighborhoods north of the reservoir and water from Barker reservoir began to overtop into neighborhoods north and east of the reservoir. As a result, the flood control stations for both reservoirs were opened and large volumes of water were dumped into Buffalo Bayou which resulted in extensive flooding along the river to the south and east of the reservoirs.

This project uses computer vision to build a passability map for road networks in a flooded area.  It relies on satellite imagery to observe the flood conditions and road data gathered through surveys conducted by gps equipped vehicles.

### Harvey Imagery
* [flood imagery]({{ "/gwu/fa19/cs1010/assets/lab5/flood.png" | absolute_url }})
* [road mask]({{ "/gwu/fa19/cs1010/assets/lab5/roadmask.png" | absolute_url }})
* [water mask]({{ "/gwu/fa19/cs1010/assets/lab5/watermask.png" | absolute_url }})
* [vegetation mask]({{ "/gwu/fa19/cs1010/assets/lab5/vegmask.png" | absolute_url }})
* [digital surface model]({{ "/gwu/fa19/cs1010/assets/lab5/dsm.png" | absolute_url }})

### Process
You may need to invert some of these layers in order to perform the intersection.

1. Intersect the road network with the detected water and store the intersection as impassible roads.
2. Subtract the impassible roads from the road network and store the subtracted road network as the remaining road network
3. Intersect the vegetation mask with the remaining road network and store the intersection as unobservable roads
4. Subtract the unobservable roads from the remaining road network and store this subtracted network as passable roads.
5. Shade the impassible roads in red, shade the unobservable roads in blue, and shade the passable roads in green.
6. Layer the individual road networks into a single road layer.
7. Layer the road layer onto the flood image.
